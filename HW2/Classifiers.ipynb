{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #2: classification\n",
    "Data source: http://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('./4year.arff')\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bankruptcy'] = (df['class']==b'1')\n",
    "df.drop(columns=['class'], inplace=True)\n",
    "df.columns = ['X{0:02d}'.format(k) for k in range(1,65)] + ['bankruptcy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X01</th>\n",
       "      <th>X02</th>\n",
       "      <th>X03</th>\n",
       "      <th>X04</th>\n",
       "      <th>X05</th>\n",
       "      <th>X06</th>\n",
       "      <th>X07</th>\n",
       "      <th>X08</th>\n",
       "      <th>X09</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9749.000000</td>\n",
       "      <td>9.771000e+03</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9773.000000</td>\n",
       "      <td>9792.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.792000e+03</td>\n",
       "      <td>9771.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9776.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9178.000000</td>\n",
       "      <td>9760.000000</td>\n",
       "      <td>9.771000e+03</td>\n",
       "      <td>9749.000000</td>\n",
       "      <td>9561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.043019</td>\n",
       "      <td>0.596404</td>\n",
       "      <td>0.130959</td>\n",
       "      <td>8.136600</td>\n",
       "      <td>6.465164e+01</td>\n",
       "      <td>-0.059273</td>\n",
       "      <td>0.059446</td>\n",
       "      <td>19.884016</td>\n",
       "      <td>1.882296</td>\n",
       "      <td>0.389040</td>\n",
       "      <td>...</td>\n",
       "      <td>7.686330e+03</td>\n",
       "      <td>-0.992263</td>\n",
       "      <td>0.035022</td>\n",
       "      <td>1.133287</td>\n",
       "      <td>0.856053</td>\n",
       "      <td>118.156064</td>\n",
       "      <td>25.194430</td>\n",
       "      <td>2.015157e+03</td>\n",
       "      <td>8.660813</td>\n",
       "      <td>35.949619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.359321</td>\n",
       "      <td>4.587122</td>\n",
       "      <td>4.559074</td>\n",
       "      <td>290.647281</td>\n",
       "      <td>1.475939e+04</td>\n",
       "      <td>6.812754</td>\n",
       "      <td>0.533344</td>\n",
       "      <td>698.697015</td>\n",
       "      <td>17.674650</td>\n",
       "      <td>4.590299</td>\n",
       "      <td>...</td>\n",
       "      <td>7.605261e+04</td>\n",
       "      <td>77.007971</td>\n",
       "      <td>8.945365</td>\n",
       "      <td>8.038201</td>\n",
       "      <td>26.393305</td>\n",
       "      <td>3230.316692</td>\n",
       "      <td>1099.260821</td>\n",
       "      <td>1.171461e+05</td>\n",
       "      <td>60.838202</td>\n",
       "      <td>483.318623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.458000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-445.910000</td>\n",
       "      <td>-0.045319</td>\n",
       "      <td>-3.794600e+05</td>\n",
       "      <td>-486.820000</td>\n",
       "      <td>-12.458000</td>\n",
       "      <td>-1.848200</td>\n",
       "      <td>-0.032371</td>\n",
       "      <td>-445.910000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.132200e+05</td>\n",
       "      <td>-7522.100000</td>\n",
       "      <td>-597.420000</td>\n",
       "      <td>-30.892000</td>\n",
       "      <td>-284.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.656000</td>\n",
       "      <td>-1.496500e+04</td>\n",
       "      <td>-0.024390</td>\n",
       "      <td>-0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.263145</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>1.047000</td>\n",
       "      <td>-5.121700e+01</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.428300</td>\n",
       "      <td>1.006675</td>\n",
       "      <td>0.294440</td>\n",
       "      <td>...</td>\n",
       "      <td>2.184000e+01</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.008768</td>\n",
       "      <td>0.885722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.356325</td>\n",
       "      <td>4.267700</td>\n",
       "      <td>4.323400e+01</td>\n",
       "      <td>2.938800</td>\n",
       "      <td>2.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.041364</td>\n",
       "      <td>0.467740</td>\n",
       "      <td>0.199290</td>\n",
       "      <td>1.591800</td>\n",
       "      <td>-5.557600e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048820</td>\n",
       "      <td>1.088700</td>\n",
       "      <td>1.161300</td>\n",
       "      <td>0.510450</td>\n",
       "      <td>...</td>\n",
       "      <td>9.503300e+02</td>\n",
       "      <td>0.043679</td>\n",
       "      <td>0.098026</td>\n",
       "      <td>0.958305</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>9.482000</td>\n",
       "      <td>6.283550</td>\n",
       "      <td>7.472900e+01</td>\n",
       "      <td>4.848900</td>\n",
       "      <td>4.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.111130</td>\n",
       "      <td>0.689255</td>\n",
       "      <td>0.410670</td>\n",
       "      <td>2.880400</td>\n",
       "      <td>5.573200e+01</td>\n",
       "      <td>0.065322</td>\n",
       "      <td>0.126940</td>\n",
       "      <td>2.691000</td>\n",
       "      <td>1.970225</td>\n",
       "      <td>0.714290</td>\n",
       "      <td>...</td>\n",
       "      <td>4.694550e+03</td>\n",
       "      <td>0.117170</td>\n",
       "      <td>0.242680</td>\n",
       "      <td>0.996163</td>\n",
       "      <td>0.211790</td>\n",
       "      <td>19.506000</td>\n",
       "      <td>9.938200</td>\n",
       "      <td>1.233450e+02</td>\n",
       "      <td>8.363800</td>\n",
       "      <td>9.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.482000</td>\n",
       "      <td>446.910000</td>\n",
       "      <td>22.769000</td>\n",
       "      <td>27146.000000</td>\n",
       "      <td>1.034100e+06</td>\n",
       "      <td>322.200000</td>\n",
       "      <td>38.618000</td>\n",
       "      <td>53209.000000</td>\n",
       "      <td>1704.800000</td>\n",
       "      <td>12.602000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.123700e+06</td>\n",
       "      <td>112.020000</td>\n",
       "      <td>226.760000</td>\n",
       "      <td>668.750000</td>\n",
       "      <td>1661.000000</td>\n",
       "      <td>251570.000000</td>\n",
       "      <td>108000.000000</td>\n",
       "      <td>1.077900e+07</td>\n",
       "      <td>5662.400000</td>\n",
       "      <td>21153.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X01          X02          X03           X04           X05  \\\n",
       "count  9791.000000  9791.000000  9791.000000   9749.000000  9.771000e+03   \n",
       "mean      0.043019     0.596404     0.130959      8.136600  6.465164e+01   \n",
       "std       0.359321     4.587122     4.559074    290.647281  1.475939e+04   \n",
       "min     -12.458000     0.000000  -445.910000     -0.045319 -3.794600e+05   \n",
       "25%       0.001321     0.263145     0.020377      1.047000 -5.121700e+01   \n",
       "50%       0.041364     0.467740     0.199290      1.591800 -5.557600e-02   \n",
       "75%       0.111130     0.689255     0.410670      2.880400  5.573200e+01   \n",
       "max      20.482000   446.910000    22.769000  27146.000000  1.034100e+06   \n",
       "\n",
       "               X06          X07           X08          X09          X10  ...  \\\n",
       "count  9791.000000  9791.000000   9773.000000  9792.000000  9791.000000  ...   \n",
       "mean     -0.059273     0.059446     19.884016     1.882296     0.389040  ...   \n",
       "std       6.812754     0.533344    698.697015    17.674650     4.590299  ...   \n",
       "min    -486.820000   -12.458000     -1.848200    -0.032371  -445.910000  ...   \n",
       "25%      -0.000578     0.003004      0.428300     1.006675     0.294440  ...   \n",
       "50%       0.000000     0.048820      1.088700     1.161300     0.510450  ...   \n",
       "75%       0.065322     0.126940      2.691000     1.970225     0.714290  ...   \n",
       "max     322.200000    38.618000  53209.000000  1704.800000    12.602000  ...   \n",
       "\n",
       "                X55          X56          X57          X58          X59  \\\n",
       "count  9.792000e+03  9771.000000  9791.000000  9776.000000  9791.000000   \n",
       "mean   7.686330e+03    -0.992263     0.035022     1.133287     0.856053   \n",
       "std    7.605261e+04    77.007971     8.945365     8.038201    26.393305   \n",
       "min   -7.132200e+05 -7522.100000  -597.420000   -30.892000  -284.380000   \n",
       "25%    2.184000e+01     0.003121     0.008768     0.885722     0.000000   \n",
       "50%    9.503300e+02     0.043679     0.098026     0.958305     0.002129   \n",
       "75%    4.694550e+03     0.117170     0.242680     0.996163     0.211790   \n",
       "max    6.123700e+06   112.020000   226.760000   668.750000  1661.000000   \n",
       "\n",
       "                 X60            X61           X62          X63           X64  \n",
       "count    9178.000000    9760.000000  9.771000e+03  9749.000000   9561.000000  \n",
       "mean      118.156064      25.194430  2.015157e+03     8.660813     35.949619  \n",
       "std      3230.316692    1099.260821  1.171461e+05    60.838202    483.318623  \n",
       "min         0.000000     -12.656000 -1.496500e+04    -0.024390     -0.000015  \n",
       "25%         5.356325       4.267700  4.323400e+01     2.938800      2.012900  \n",
       "50%         9.482000       6.283550  7.472900e+01     4.848900      4.041600  \n",
       "75%        19.506000       9.938200  1.233450e+02     8.363800      9.413500  \n",
       "max    251570.000000  108000.000000  1.077900e+07  5662.400000  21153.000000  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.bankruptcy == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(), inplace=True)\n",
    "df.isna().sum()\n",
    "X_imp = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = X_imp[:, :-1], X_imp[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6854, 64)\n",
      "(2938, 64)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as skpre\n",
    "\n",
    "stdsc = skpre.StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "print(X_train_std.shape)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "print(X_test_std.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the 2 most important features\n",
    "using Logistic Regression with L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9474759264662971\n",
      "Test accuracy: 0.9469026548672567\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l1',\n",
    "                       C=0.01,\n",
    "                       solver='liblinear') # complete\n",
    "y_train=np.int64(y_train)\n",
    "y_test=np.int64(y_test)\n",
    "lr.fit(X_train_std, y_train)\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_[lr.coef_!=0].shape # check the number of the features with non-zero weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine X_train_std and X_test_std\n",
    "X_train_std = X_train_std[:, lr.coef_[0]!=0]\n",
    "X_test_std = X_test_std[:, lr.coef_[0]!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply LR / SVM / Decision Tree below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.946892325649256\n",
      "Test accuracy: 0.9469026548672567\n"
     ]
    }
   ],
   "source": [
    "## C=1\n",
    "lr = LogisticRegression(penalty='l2',C=1,solver='lbfgs',multi_class='ovr')\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.946892325649256\n",
      "Test accuracy: 0.9469026548672567\n"
     ]
    }
   ],
   "source": [
    "## C=10\n",
    "lr = LogisticRegression(penalty='l2',C=10,solver='lbfgs',multi_class='ovr')\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.946892325649256\n",
      "Test accuracy: 0.9469026548672567\n"
     ]
    }
   ],
   "source": [
    "## C=100\n",
    "lr = LogisticRegression(penalty='l2',C=100,solver='lbfgs',multi_class='ovr')\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.946892325649256\n",
      "Test accuracy: 0.9469026548672567\n"
     ]
    }
   ],
   "source": [
    "## C=0.1\n",
    "lr = LogisticRegression(penalty='l2',C=0.1,solver='lbfgs',multi_class='ovr')\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9470382258535162\n",
      "Test accuracy: 0.9469026548672567\n"
     ]
    }
   ],
   "source": [
    "## C=0.01\n",
    "lr = LogisticRegression(penalty='l2',C=0.01,solver='lbfgs',multi_class='ovr')\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9474759264662971\n",
      "Test accuracy: 0.9472430224642614\n"
     ]
    }
   ],
   "source": [
    "## C=1 and linear kernal\n",
    "svm=SVC(kernel='linear',C=1)\n",
    "svm.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', svm.score(X_train_std, y_train))\n",
    "print('Test accuracy:', svm.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9474759264662971\n",
      "Test accuracy: 0.9472430224642614\n"
     ]
    }
   ],
   "source": [
    "## C=10 and linear kernal\n",
    "svm=SVC(kernel='linear',C=10)\n",
    "svm.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', svm.score(X_train_std, y_train))\n",
    "print('Test accuracy:', svm.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9474759264662971\n",
      "Test accuracy: 0.9472430224642614\n"
     ]
    }
   ],
   "source": [
    "## C=0.01 and linear kernal\n",
    "svm=SVC(kernel='linear',C=0.1)\n",
    "svm.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', svm.score(X_train_std, y_train))\n",
    "print('Test accuracy:', svm.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9482054274875985\n",
      "Test accuracy: 0.9472430224642614\n"
     ]
    }
   ],
   "source": [
    "## C=1 and RBF kernal\n",
    "svm=SVC(kernel='rbf',C=1)\n",
    "svm.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', svm.score(X_train_std, y_train))\n",
    "print('Test accuracy:', svm.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.948497227896119\n",
      "Test accuracy: 0.9458815520762424\n"
     ]
    }
   ],
   "source": [
    "## Gini with max_depth as 4\n",
    "tm=DecisionTreeClassifier(criterion='gini',max_depth=4)\n",
    "tm.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', tm.score(X_train_std, y_train))\n",
    "print('Test accuracy:', tm.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9474759264662971\n",
      "Test accuracy: 0.9472430224642614\n"
     ]
    }
   ],
   "source": [
    "## Gini with max_depth as 2\n",
    "tm=DecisionTreeClassifier(criterion='gini',max_depth=2)\n",
    "tm.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', tm.score(X_train_std, y_train))\n",
    "print('Test accuracy:', tm.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9493726291216807\n",
      "Test accuracy: 0.944860449285228\n"
     ]
    }
   ],
   "source": [
    "## Gini with max_depth as 5\n",
    "tm=DecisionTreeClassifier(criterion='gini',max_depth=5)\n",
    "tm.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', tm.score(X_train_std, y_train))\n",
    "print('Test accuracy:', tm.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9474759264662971\n",
      "Test accuracy: 0.9472430224642614\n"
     ]
    }
   ],
   "source": [
    "## Entropy with max_depth as 2\n",
    "tm=DecisionTreeClassifier(criterion='entropy',max_depth=2)\n",
    "tm.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', tm.score(X_train_std, y_train))\n",
    "print('Test accuracy:', tm.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')\n",
    "\n",
    "    # highlight test samples\n",
    "    if test_idx:\n",
    "        # plot all samples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='',\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-44-b702a6ce12dd>:36: MatplotlibDeprecationWarning: Using a string of single character colors as a color sequence is deprecated since 3.2 and will be removed two minor releases later. Use an explicit list instead.\n",
      "  plt.scatter(X_test[:, 0],\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "to_clean=pd.DataFrame(np.hstack([X_combined_std,y_combined[:,None]]),columns=['X1','X2','y'])\n",
    "to_clean=to_clean[(to_clean.X1>-100)&(to_clean.X2>-100)]\n",
    "X_combined_std=to_clean[['X1','X2']].values\n",
    "y_combined=to_clean.y\n",
    "\n",
    "plot_decision_regions(X=X_combined_std, y=y_combined,\n",
    "                      classifier=lr, test_idx=range(0, 50))\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/03_01.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
