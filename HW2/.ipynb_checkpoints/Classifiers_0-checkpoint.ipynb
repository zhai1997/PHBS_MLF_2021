{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #2: classification\n",
    "Data source: http://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('4year.arff')\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bankruptcy'] = (df['class']==b'1')\n",
    "df.drop(columns=['class'], inplace=True)\n",
    "df.columns = ['X{0:02d}'.format(k) for k in range(1,65)] + ['bankruptcy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X01</th>\n",
       "      <th>X02</th>\n",
       "      <th>X03</th>\n",
       "      <th>X04</th>\n",
       "      <th>X05</th>\n",
       "      <th>X06</th>\n",
       "      <th>X07</th>\n",
       "      <th>X08</th>\n",
       "      <th>X09</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9749.000000</td>\n",
       "      <td>9.771000e+03</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9773.000000</td>\n",
       "      <td>9792.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.792000e+03</td>\n",
       "      <td>9771.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9776.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9178.000000</td>\n",
       "      <td>9760.000000</td>\n",
       "      <td>9.771000e+03</td>\n",
       "      <td>9749.000000</td>\n",
       "      <td>9561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.043019</td>\n",
       "      <td>0.596404</td>\n",
       "      <td>0.130959</td>\n",
       "      <td>8.136600</td>\n",
       "      <td>6.465164e+01</td>\n",
       "      <td>-0.059273</td>\n",
       "      <td>0.059446</td>\n",
       "      <td>19.884016</td>\n",
       "      <td>1.882296</td>\n",
       "      <td>0.389040</td>\n",
       "      <td>...</td>\n",
       "      <td>7.686330e+03</td>\n",
       "      <td>-0.992263</td>\n",
       "      <td>0.035022</td>\n",
       "      <td>1.133287</td>\n",
       "      <td>0.856053</td>\n",
       "      <td>118.156064</td>\n",
       "      <td>25.194430</td>\n",
       "      <td>2.015157e+03</td>\n",
       "      <td>8.660813</td>\n",
       "      <td>35.949619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.359321</td>\n",
       "      <td>4.587122</td>\n",
       "      <td>4.559074</td>\n",
       "      <td>290.647281</td>\n",
       "      <td>1.475939e+04</td>\n",
       "      <td>6.812754</td>\n",
       "      <td>0.533344</td>\n",
       "      <td>698.697015</td>\n",
       "      <td>17.674650</td>\n",
       "      <td>4.590299</td>\n",
       "      <td>...</td>\n",
       "      <td>7.605261e+04</td>\n",
       "      <td>77.007971</td>\n",
       "      <td>8.945365</td>\n",
       "      <td>8.038201</td>\n",
       "      <td>26.393305</td>\n",
       "      <td>3230.316692</td>\n",
       "      <td>1099.260821</td>\n",
       "      <td>1.171461e+05</td>\n",
       "      <td>60.838202</td>\n",
       "      <td>483.318623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.458000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-445.910000</td>\n",
       "      <td>-0.045319</td>\n",
       "      <td>-3.794600e+05</td>\n",
       "      <td>-486.820000</td>\n",
       "      <td>-12.458000</td>\n",
       "      <td>-1.848200</td>\n",
       "      <td>-0.032371</td>\n",
       "      <td>-445.910000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.132200e+05</td>\n",
       "      <td>-7522.100000</td>\n",
       "      <td>-597.420000</td>\n",
       "      <td>-30.892000</td>\n",
       "      <td>-284.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.656000</td>\n",
       "      <td>-1.496500e+04</td>\n",
       "      <td>-0.024390</td>\n",
       "      <td>-0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.263145</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>1.047000</td>\n",
       "      <td>-5.121700e+01</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.428300</td>\n",
       "      <td>1.006675</td>\n",
       "      <td>0.294440</td>\n",
       "      <td>...</td>\n",
       "      <td>2.184000e+01</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.008768</td>\n",
       "      <td>0.885722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.356325</td>\n",
       "      <td>4.267700</td>\n",
       "      <td>4.323400e+01</td>\n",
       "      <td>2.938800</td>\n",
       "      <td>2.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.041364</td>\n",
       "      <td>0.467740</td>\n",
       "      <td>0.199290</td>\n",
       "      <td>1.591800</td>\n",
       "      <td>-5.557600e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048820</td>\n",
       "      <td>1.088700</td>\n",
       "      <td>1.161300</td>\n",
       "      <td>0.510450</td>\n",
       "      <td>...</td>\n",
       "      <td>9.503300e+02</td>\n",
       "      <td>0.043679</td>\n",
       "      <td>0.098026</td>\n",
       "      <td>0.958305</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>9.482000</td>\n",
       "      <td>6.283550</td>\n",
       "      <td>7.472900e+01</td>\n",
       "      <td>4.848900</td>\n",
       "      <td>4.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.111130</td>\n",
       "      <td>0.689255</td>\n",
       "      <td>0.410670</td>\n",
       "      <td>2.880400</td>\n",
       "      <td>5.573200e+01</td>\n",
       "      <td>0.065322</td>\n",
       "      <td>0.126940</td>\n",
       "      <td>2.691000</td>\n",
       "      <td>1.970225</td>\n",
       "      <td>0.714290</td>\n",
       "      <td>...</td>\n",
       "      <td>4.694550e+03</td>\n",
       "      <td>0.117170</td>\n",
       "      <td>0.242680</td>\n",
       "      <td>0.996163</td>\n",
       "      <td>0.211790</td>\n",
       "      <td>19.506000</td>\n",
       "      <td>9.938200</td>\n",
       "      <td>1.233450e+02</td>\n",
       "      <td>8.363800</td>\n",
       "      <td>9.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.482000</td>\n",
       "      <td>446.910000</td>\n",
       "      <td>22.769000</td>\n",
       "      <td>27146.000000</td>\n",
       "      <td>1.034100e+06</td>\n",
       "      <td>322.200000</td>\n",
       "      <td>38.618000</td>\n",
       "      <td>53209.000000</td>\n",
       "      <td>1704.800000</td>\n",
       "      <td>12.602000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.123700e+06</td>\n",
       "      <td>112.020000</td>\n",
       "      <td>226.760000</td>\n",
       "      <td>668.750000</td>\n",
       "      <td>1661.000000</td>\n",
       "      <td>251570.000000</td>\n",
       "      <td>108000.000000</td>\n",
       "      <td>1.077900e+07</td>\n",
       "      <td>5662.400000</td>\n",
       "      <td>21153.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X01          X02          X03           X04           X05  \\\n",
       "count  9791.000000  9791.000000  9791.000000   9749.000000  9.771000e+03   \n",
       "mean      0.043019     0.596404     0.130959      8.136600  6.465164e+01   \n",
       "std       0.359321     4.587122     4.559074    290.647281  1.475939e+04   \n",
       "min     -12.458000     0.000000  -445.910000     -0.045319 -3.794600e+05   \n",
       "25%       0.001321     0.263145     0.020377      1.047000 -5.121700e+01   \n",
       "50%       0.041364     0.467740     0.199290      1.591800 -5.557600e-02   \n",
       "75%       0.111130     0.689255     0.410670      2.880400  5.573200e+01   \n",
       "max      20.482000   446.910000    22.769000  27146.000000  1.034100e+06   \n",
       "\n",
       "               X06          X07           X08          X09          X10  ...  \\\n",
       "count  9791.000000  9791.000000   9773.000000  9792.000000  9791.000000  ...   \n",
       "mean     -0.059273     0.059446     19.884016     1.882296     0.389040  ...   \n",
       "std       6.812754     0.533344    698.697015    17.674650     4.590299  ...   \n",
       "min    -486.820000   -12.458000     -1.848200    -0.032371  -445.910000  ...   \n",
       "25%      -0.000578     0.003004      0.428300     1.006675     0.294440  ...   \n",
       "50%       0.000000     0.048820      1.088700     1.161300     0.510450  ...   \n",
       "75%       0.065322     0.126940      2.691000     1.970225     0.714290  ...   \n",
       "max     322.200000    38.618000  53209.000000  1704.800000    12.602000  ...   \n",
       "\n",
       "                X55          X56          X57          X58          X59  \\\n",
       "count  9.792000e+03  9771.000000  9791.000000  9776.000000  9791.000000   \n",
       "mean   7.686330e+03    -0.992263     0.035022     1.133287     0.856053   \n",
       "std    7.605261e+04    77.007971     8.945365     8.038201    26.393305   \n",
       "min   -7.132200e+05 -7522.100000  -597.420000   -30.892000  -284.380000   \n",
       "25%    2.184000e+01     0.003121     0.008768     0.885722     0.000000   \n",
       "50%    9.503300e+02     0.043679     0.098026     0.958305     0.002129   \n",
       "75%    4.694550e+03     0.117170     0.242680     0.996163     0.211790   \n",
       "max    6.123700e+06   112.020000   226.760000   668.750000  1661.000000   \n",
       "\n",
       "                 X60            X61           X62          X63           X64  \n",
       "count    9178.000000    9760.000000  9.771000e+03  9749.000000   9561.000000  \n",
       "mean      118.156064      25.194430  2.015157e+03     8.660813     35.949619  \n",
       "std      3230.316692    1099.260821  1.171461e+05    60.838202    483.318623  \n",
       "min         0.000000     -12.656000 -1.496500e+04    -0.024390     -0.000015  \n",
       "25%         5.356325       4.267700  4.323400e+01     2.938800      2.012900  \n",
       "50%         9.482000       6.283550  7.472900e+01     4.848900      4.041600  \n",
       "75%        19.506000       9.938200  1.233450e+02     8.363800      9.413500  \n",
       "max    251570.000000  108000.000000  1.077900e+07  5662.400000  21153.000000  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.bankruptcy == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(), inplace=True)\n",
    "df.isna().sum()\n",
    "X_imp = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:806: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:806: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = X_imp[:, :-1], X_imp[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6854, 64)\n",
      "(2938, 64)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as skpre\n",
    "\n",
    "stdsc = skpre.StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "print(X_train_std.shape)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "print(X_test_std.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the 2 most important features\n",
    "using Logistic Regression with L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "# and put more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(...) # complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0030835, 0.48218, 0.13073, ..., 116.71, 3.1275, 0.44928],\n",
       "       [-0.04981, 0.27968, 0.36726, ..., 118.54, 3.079, 2.439],\n",
       "       [0.17175, 0.82369, -0.064784, ..., 112.12, 3.2554, 2.9258],\n",
       "       ...,\n",
       "       [0.19286, 0.48409, 0.12599, ..., 74.98, 4.868, 5.3827],\n",
       "       [-0.19392, 2.5617, -0.50016, ..., 306.08, 1.1925, 0.68896],\n",
       "       [0.15221, 0.50803, 0.4259, ..., 68.939, 5.2945, 29.021]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-bac0dc64404e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;31m# check the number of the features with non-zero weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "lr.coef_[lr.coef_!=0].shape # check the number of the features with non-zero weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine X_train_std and X_test_std\n",
    "X_train_std = X_train_std[:, lr.coef_[0]!=0]\n",
    "X_test_std = X_test_std[:, lr.coef_[0]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply LR / SVM / Decision Tree below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1')\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')\n",
    "\n",
    "    # highlight test samples\n",
    "    if test_idx:\n",
    "        # plot all samples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='',\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "plot_decision_regions(X=X_combined_std, y=y_combined,\n",
    "                      classifier=lr, test_idx=range(0, 50))\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/03_01.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
